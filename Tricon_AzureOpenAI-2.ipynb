{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc83df22-3c42-4114-9cba-172051913b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d224c2-6214-498e-855e-91f436a3aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain import LLMChain\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4deaeb8-4cd4-47b5-acae-bf20333d5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_base=<openai_api_base>\n",
    "openai_api_version=<openai_api_version>\n",
    "deployment_name=<deployment_name>\n",
    "openai_api_key = <openai_api_key>\n",
    "openai_api_type=<openai_api_type>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36b62f68-d2c2-4362-9a9d-1584535ea99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ual-laptop\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_version=openai_api_version,\n",
    "    deployment_name=deployment_name,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_type=openai_api_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe6109c-40e8-45f5-9f40-77d350a3d5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 573 words\n",
      "Grade Level: High School\n",
      "Discipline: Biology\n",
      "Blooms Level: Analysis\n",
      "Learning_Objectives: Understand the evolutionary development of snakeflies\n",
      "Learning_Facets: Genetic analysis, Phylogenetic analysis\n",
      "----------------------------------------------------------------------------------------\n",
      "Length: 660 words\n",
      "Grade Level: unknown\n",
      "Discipline: Physics\n",
      "Blooms Level: Application\n",
      "Learning_Objectives: Understand the concept of quantum tunneling and its use in creating quantum sensors and other electronic devices\n",
      "Learning_Facets: Experimental analysis, problem-solving\n",
      "----------------------------------------------------------------------------------------\n",
      "Length: 450 words\n",
      "Grade Level: High School\n",
      "Discipline: Biochemistry\n",
      "Blooms Level: Analysis\n",
      "Learning_Objectives: Understand the evolutionary pattern of regulatory proteins and how they acquire and lose functions over time\n",
      "Learning_Facets: Computer modeling, scientific research\n",
      "----------------------------------------------------------------------------------------\n",
      "Length: 500 words\n",
      "Grade Level: High School\n",
      "Discipline: Chemistry\n",
      "Blooms Level: Application\n",
      "Learning_Objectives: Understand the role of alcohols in acid-base reactions and the importance of hydrogen bonding in the formation of effective Brnsted bases\n",
      "Learning_Facets: Experimental analysis, problem-solving\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m                 time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    109\u001b[0m main_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mual-laptop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mresources\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 110\u001b[0m process_pdfs_in_directory(main_directory)\n",
      "Cell \u001b[1;32mIn[5], line 87\u001b[0m, in \u001b[0;36mprocess_pdfs_in_directory\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     81\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m     82\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m\"\u001b[39m: article_text,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m: example,\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: format_instructions\n\u001b[0;32m     86\u001b[0m }\n\u001b[1;32m---> 87\u001b[0m response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke(inputs)\n\u001b[0;32m     88\u001b[0m json_string \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m```json\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     89\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_string)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2495\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2494\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2495\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   2496\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:170\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    167\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    169\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    171\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    172\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    173\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    174\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    175\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    176\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    177\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    179\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    180\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:599\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    593\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    598\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:417\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    383\u001b[0m     messages: List[List[BaseMessage]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    392\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pass a sequence of prompts to the model and return model generations.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    This method should make use of batched calls for models that expose a batched\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m            prompt and additional model provider-specific output.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_invocation_params(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    418\u001b[0m     options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop}\n\u001b[0;32m    419\u001b[0m     inheritable_metadata \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(metadata \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ls_params(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    422\u001b[0m     }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:571\u001b[0m, in \u001b[0;36mChatOpenAI._get_invocation_params\u001b[1;34m(self, stop, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_invocation_params\u001b[39m(\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m, stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    567\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    568\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the parameters used to invoke the model.\"\"\"\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_get_invocation_params(stop\u001b[38;5;241m=\u001b[39mstop),\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_params,\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    574\u001b[0m     }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:355\u001b[0m, in \u001b[0;36mBaseChatModel._get_invocation_params\u001b[1;34m(self, stop, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_invocation_params\u001b[39m(\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    352\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    354\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 355\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict()\n\u001b[0;32m    356\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:942\u001b[0m, in \u001b[0;36mBaseChatModel.dict\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m    941\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a dictionary of the LLM.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m     starter_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifying_params)\n\u001b[0;32m    943\u001b[0m     starter_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm_type\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m starter_dict\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:231\u001b[0m, in \u001b[0;36mAzureChatOpenAI._identifying_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_identifying_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    230\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the identifying parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_params}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:220\u001b[0m, in \u001b[0;36mAzureChatOpenAI._default_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the default parameters for calling OpenAI API.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_default_params\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\utils\\openai.py:10\u001b[0m, in \u001b[0;36mis_openai_v1\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_openai_v1\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return whether OpenAI API is v1 or more.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     _version \u001b[38;5;241m=\u001b[39m parse(version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _version\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:1008\u001b[0m, in \u001b[0;36mversion\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \n\u001b[0;32m   1004\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distribution(distribution_name)\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:981\u001b[0m, in \u001b[0;36mdistribution\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[0;32m    976\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \n\u001b[0;32m    978\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Distribution\u001b[38;5;241m.\u001b[39mfrom_name(distribution_name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:563\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA distribution name is required.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdiscover(name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:915\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Find metadata directories in paths heuristically.\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m prepared \u001b[38;5;241m=\u001b[39m Prepared(name)\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m--> 915\u001b[0m     path\u001b[38;5;241m.\u001b[39msearch(prepared) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(FastPath, paths)\n\u001b[0;32m    916\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:813\u001b[0m, in \u001b[0;36mFastPath.search\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmtime)\u001b[38;5;241m.\u001b[39msearch(name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:818\u001b[0m, in \u001b[0;36mFastPath.mtime\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmtime\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[1;32m--> 818\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mstat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\u001b[38;5;241m.\u001b[39mst_mtime\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup\u001b[38;5;241m.\u001b[39mcache_clear()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"Language\", description=\"Language used in the article\"),\n",
    "    ResponseSchema(name=\"Length\", description=\"Length of the article in words\"),\n",
    "    ResponseSchema(name=\"Grade_Level\", description=\"Grade level of the content\"),\n",
    "    ResponseSchema(name=\"Discipline\", description=\"Discipline or subject of the article\"),\n",
    "    ResponseSchema(name=\"Blooms_Level\", description=\"Bloom's taxonomy level of the content\"),\n",
    "    ResponseSchema(name=\"Learning_Objectives\", description=\"Learning objectives covered in the article\"),\n",
    "    ResponseSchema(name=\"Learning_Facets\", description=\"Learning facets addressed in the article\")\n",
    "]\n",
    "\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "example = '''{\n",
    "    \"Language\": \"English\",\n",
    "    \"Length\": \"1500 words\",\n",
    "    \"Grade_Level\": \"High School\",\n",
    "    \"Discipline\": \"Chemistry\",\n",
    "    \"Blooms_Level\": \"Application\",\n",
    "    \"Learning_Objectives\": \"Understand acid-base theories\",\n",
    "    \"Learning_Facets\": \"Experimental analysis, problem-solving\"\n",
    "}'''\n",
    "\n",
    "\n",
    "template = \"\"\"\\\n",
    "You are an educational curriculum expert system tasked to find specific information for the article. \n",
    "Identify the following items from the review text:\n",
    "- Language used in the article\n",
    "- Length of the article in words\n",
    "- Grade level of the content (e.g., 10th grade, 12th grade, University)\n",
    "- Discipline or subject of the article\n",
    "- Bloom's taxonomy level of the content\n",
    "- Learning objectives covered in the article\n",
    "- Learning facets addressed in the article\n",
    "\n",
    "The review text is delimited with triple backticks.\n",
    "\n",
    "Take your time to analyze the review text and find the required information.\n",
    "Output the response in the desired format as given in {example} but don't use the same value.\n",
    "\n",
    "Make your response as short as possible.\n",
    "Make sure to answer in the correct format.\n",
    "Review text: ```{article}```\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "If the information isn't present retry again two times and then use 'unknown' as the value, not null or None.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "def process_pdfs_in_directory(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                \n",
    "                try:\n",
    "                    # Extract and clean text from the PDF\n",
    "                    article_text = extract_text_from_pdf(pdf_path)\n",
    "                    article_text = clean_text(article_text)\n",
    "                    \n",
    "                    # Use the LLMChain to process the prompt\n",
    "                    chain = prompt | llm\n",
    "                    inputs = {\n",
    "                        \"article\": article_text,\n",
    "                        \"example\": example,\n",
    "                        \"format_instructions\": format_instructions\n",
    "                    }\n",
    "                    response = chain.invoke(inputs)\n",
    "                    json_string = response.content.strip('```json\\n').strip('\\n```')\n",
    "                    data = json.loads(json_string)\n",
    "                    language = data.get(\"Language\")\n",
    "                    length = data.get(\"Length\")\n",
    "                    grade_level = data.get(\"Grade_Level\")\n",
    "                    discipline = data.get(\"Discipline\")\n",
    "                    blooms_level = data.get(\"Blooms_Level\")\n",
    "                    Learning_Objectives = data.get(\"Learning_Objectives\")\n",
    "                    Learning_Facets = data.get(\"Learning_Facets\")\n",
    "                    print(f\"Length: {length}\")\n",
    "                    print(f\"Grade Level: {grade_level}\")\n",
    "                    print(f\"Discipline: {discipline}\")\n",
    "                    print(f\"Blooms Level: {blooms_level}\")\n",
    "                    print(f\"Learning_Objectives: {Learning_Objectives}\")\n",
    "                    print(f\"Learning_Facets: {Learning_Facets}\")\n",
    "                    print(\"----------------------------------------------------------------------------------------\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {pdf_path}: {e}\")\n",
    "                    print(\"----------------------------------------------------------------------------------------\")\n",
    "                time.sleep(3)\n",
    "                \n",
    "main_directory = r\"C:\\Users\\ual-laptop\\Downloads\\resources\"\n",
    "process_pdfs_in_directory(main_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
